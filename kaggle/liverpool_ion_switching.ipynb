{"cells":[{"metadata":{"id":"z2c-9CUKVzGY","colab_type":"text"},"cell_type":"markdown","source":"## 0 prefix work"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"id":"-bIkjfgWGB6X","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression, Ridge, SGDRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, f1_score, mean_absolute_error, make_scorer\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom functools import partial\nimport scipy as sp\n\nimport time\nimport datetime\n\nimport gc","execution_count":47,"outputs":[]},{"metadata":{"id":"FG9PpsjGPbnW","colab_type":"text"},"cell_type":"markdown","source":"## 1 data process"},{"metadata":{"id":"REjLqK9xTU5h","colab_type":"text"},"cell_type":"markdown","source":"### 1.1 mem ruduce function"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"id":"P1QNv-ivGB6h","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# dataframe reduction function\ndef reduce_mem_usage(df, verbose=True):    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        if col != 'time':\n            col_type = df[col].dtypes\n            if col_type in numerics:\n                c_min = df[col].min()\n                c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: \n      print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n","execution_count":48,"outputs":[]},{"metadata":{"id":"c6RagCVPTeBo","colab_type":"text"},"cell_type":"markdown","source":"### 1.2 params define"},{"metadata":{"id":"Cb83-f3vTjZe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":437},"outputId":"859ece3b-3038-48e3-cffa-fac479dd1c66","trusted":true},"cell_type":"code","source":"window_sizes = [10, 50]\ntrain_df = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\ny = train_df['open_channels']\ntest_df = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')\ncol = [c for c in train_df.columns if c not in ['time', 'open_channels', 'group']]\nseed_random = 42\nlr_xgb = 0.1\nmax_depth_xgb = 10\nnum_boost_round_xgb = 2000\n\nparams_xgb = {'colsample_bytree': 0.375,\n              'learning_rate': lr_xgb,\n              'max_depth': max_depth_xgb, \n              'subsample': 1, \n              'objective':'reg:squarederror',\n              'eval_metric':'rmse'}","execution_count":49,"outputs":[]},{"metadata":{"id":"fKW6DM3LPJGE","colab_type":"text"},"cell_type":"markdown","source":"## 2 feature engineering"},{"metadata":{"id":"1drihkOSPI5a","colab_type":"text"},"cell_type":"markdown","source":"### 2.1 feature function"},{"metadata":{"id":"_CGJUufGMX2Q","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# feature, stat feature\ndef features(df, window_sizes):\n\n    # op1 for stat feature\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index // 25_000\n    df['batch_index'] = df.index  - (df.batch * 25_000)\n    df['batch_slices'] = df['batch_index']  // 2500\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n      d = {}\n      d['mean'+c] = df.groupby([c])['signal'].mean()\n      d['median'+c] = df.groupby([c])['signal'].median()\n      d['max'+c] = df.groupby([c])['signal'].max()\n      d['min'+c] = df.groupby([c])['signal'].min()\n      d['std'+c] = df.groupby([c])['signal'].std()\n      d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n      d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n      d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n      d['range'+c] = d['max'+c] - d['min'+c]\n      d['maxtomin'+c] = d['max'+c] / d['min'+c]\n      d['abs_avg'+c] = (d['abs_min'+c] + d['abs_max'+c]) / 2\n      for v in d:\n        df[v] = df[c].map(d[v].to_dict())\n            # add shifts_1\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n      df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n      df['signal_shift_-1'][i] = np.nan\n    \n    # add shifts_2 - my upgrade\n    df['signal_shift_+2'] = [0,] + [1,] + list(df['signal'].values[:-2])\n    df['signal_shift_-2'] = list(df['signal'].values[2:]) + [0] + [1]\n    for i in df[df['batch_index']==0].index:\n      df['signal_shift_+2'][i] = np.nan\n    for i in df[df['batch_index']==1].index:\n        df['signal_shift_+2'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n      df['signal_shift_-2'][i] = np.nan\n    for i in df[df['batch_index']==49998].index:\n      df['signal_shift_-2'][i] = np.nan\n    \n    df = df.drop(columns=['batch', 'batch_index', 'batch_slices', 'batch_slices2'])\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels']]:\n      df[c+'_msignal'] = df[c] - df['signal']\n\n    # op2 for window_size feature\n    for window in window_sizes:\n      df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n      df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n      df[\"rolling_var_\" + str(window)] = df['signal'].rolling(window=window).var()\n      df[\"rolling_min_\" + str(window)] = df['signal'].rolling(window=window).min()\n      df[\"rolling_max_\" + str(window)] = df['signal'].rolling(window=window).max()\n        \n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n    gc.collect()\n    return df\n","execution_count":50,"outputs":[]},{"metadata":{"id":"CzlFWUkmXigb","colab_type":"text"},"cell_type":"markdown","source":"### 2.2 transform df to ready to use data"},{"metadata":{"id":"ER3fj5E5XJ3g","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_df = features(train_df, window_sizes)\ntest_df = features(test_df, window_sizes)\ntrain_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)\n\nX_train, X_valid, y_train, y_valid = train_test_split(train_df[col], y, test_size=0.3, random_state=seed_random)","execution_count":51,"outputs":[{"output_type":"stream","text":"Mem. usage decreased to 681.88 Mb (72.9% reduction)\nMem. usage decreased to 270.84 Mb (72.7% reduction)\n","name":"stdout"}]},{"metadata":{"id":"eEXVH0TnPgHN","colab_type":"text"},"cell_type":"markdown","source":"## 3 model"},{"metadata":{"id":"5Ana-214TI-U","colab_type":"text"},"cell_type":"markdown","source":"### 3.1 start from a baseline"},{"metadata":{"id":"IjLMb_UaTGyc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Thanks to https://www.kaggle.com/teejmahal20/3-simple-ideas-ensemble\ntrain_set = xgb.DMatrix(X_train, y_train)\nval_set = xgb.DMatrix(X_valid, y_valid)\ndel X_train, X_valid, y_train, y_valid\ngc.collect()\n\nmodelx = xgb.train(params_xgb, \n                   train_set, \n                   num_boost_round=num_boost_round_xgb, \n                   evals=[(train_set, 'train'), (val_set, 'val')], \n                   verbose_eval=50, \n                   early_stopping_rounds=250)\ndel train_set, val_set\ngc.collect()","execution_count":52,"outputs":[{"output_type":"stream","text":"[0]\ttrain-rmse:3.19457\tval-rmse:3.20178\nMultiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n\nWill train until val-rmse hasn't improved in 250 rounds.\n[50]\ttrain-rmse:1.57968\tval-rmse:1.58069\n[100]\ttrain-rmse:1.57939\tval-rmse:1.58074\n[150]\ttrain-rmse:1.57924\tval-rmse:1.58074\n[200]\ttrain-rmse:1.57909\tval-rmse:1.58075\n[250]\ttrain-rmse:1.57901\tval-rmse:1.58076\n[300]\ttrain-rmse:1.57894\tval-rmse:1.58078\nStopping. Best iteration:\n[53]\ttrain-rmse:1.57961\tval-rmse:1.58066\n\n","name":"stdout"},{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"21"},"metadata":{}}]},{"metadata":{"id":"tL4-fpunGlOq","colab_type":"text"},"cell_type":"markdown","source":"## 4 predict and submmit"},{"metadata":{"id":"YaNIzBWJGuum","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# predict\ny_xgb_pred = modelx.predict(xgb.DMatrix(test_df[col]))\ny_pred_train_xgb = modelx.predict(xgb.DMatrix(train_df[col]))\ngc.collect()\nprint('XGB score {0:.4f}'.format(np.mean(f1_score(y, np.round(np.clip(y_pred_train_xgb,0,10)).astype(int), average=\"macro\"))))\n\n# submmit\ntest_df['open_channels'] = y_xgb_pred\ntest_df[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')","execution_count":53,"outputs":[{"output_type":"stream","text":"XGB score 0.3540\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'test' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-c38163ddf5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# submmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_channels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_xgb_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'open_channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.4f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"]}]},{"metadata":{"id":"lk0rB7ueKTXR","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}},"colab":{"name":"liverpool-ion-switching.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":4}