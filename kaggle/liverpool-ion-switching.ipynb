{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "liverpool-ion-switching.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "qt3EbQPdGB6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "-bIkjfgWGB6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, SGDRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, f1_score, mean_absolute_error, make_scorer\n",
        "import lightgbm as lgb\n",
        "\n",
        "from functools import partial\n",
        "import scipy as sp\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG9PpsjGPbnW",
        "colab_type": "text"
      },
      "source": [
        "## 1 data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "P1QNv-ivGB6h",
        "colab_type": "code",
        "colab": {},
        "outputId": "70113798-27fa-45ee-b29b-1726ba12b3f8"
      },
      "source": [
        "# dataframe reduction function\n",
        "def reduce_mem_usage(df, verbose=True):    \n",
        "  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "  start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "      if col != 'time':\n",
        "        col_type = df[col].dtypes\n",
        "          if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "              c_max = df[col].max()\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                  if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                  elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                  elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                  elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "                else:\n",
        "                  if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                  elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                  else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: \n",
        "      print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQsDOPwrULZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKW6DM3LPJGE",
        "colab_type": "text"
      },
      "source": [
        "## 2 feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1drihkOSPI5a",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CGJUufGMX2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature, stat feature\n",
        "def features(df):\n",
        "    df = df.sort_values(by=['time']).reset_index(drop=True)\n",
        "    df.index = ((df.time * 10_000) - 1).values\n",
        "    df['batch'] = df.index // 25_000\n",
        "    df['batch_index'] = df.index  - (df.batch * 25_000)\n",
        "    df['batch_slices'] = df['batch_index']  // 2500\n",
        "    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n",
        "    \n",
        "    for c in ['batch','batch_slices2']:\n",
        "        d = {}\n",
        "        d['mean'+c] = df.groupby([c])['signal'].mean()\n",
        "        d['median'+c] = df.groupby([c])['signal'].median()\n",
        "        d['max'+c] = df.groupby([c])['signal'].max()\n",
        "        d['min'+c] = df.groupby([c])['signal'].min()\n",
        "        d['std'+c] = df.groupby([c])['signal'].std()\n",
        "        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
        "        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n",
        "        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n",
        "        d['range'+c] = d['max'+c] - d['min'+c]\n",
        "        d['maxtomin'+c] = d['max'+c] / d['min'+c]\n",
        "        d['abs_avg'+c] = (d['abs_min'+c] + d['abs_max'+c]) / 2\n",
        "        for v in d:\n",
        "            df[v] = df[c].map(d[v].to_dict())\n",
        "            # add shifts_1\n",
        "    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n",
        "    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n",
        "    for i in df[df['batch_index']==0].index:\n",
        "        df['signal_shift_+1'][i] = np.nan\n",
        "    for i in df[df['batch_index']==49999].index:\n",
        "        df['signal_shift_-1'][i] = np.nan\n",
        "    \n",
        "    # add shifts_2 - my upgrade\n",
        "    df['signal_shift_+2'] = [0,] + [1,] + list(df['signal'].values[:-2])\n",
        "    df['signal_shift_-2'] = list(df['signal'].values[2:]) + [0] + [1]\n",
        "    for i in df[df['batch_index']==0].index:\n",
        "        df['signal_shift_+2'][i] = np.nan\n",
        "    for i in df[df['batch_index']==1].index:\n",
        "        df['signal_shift_+2'][i] = np.nan\n",
        "    for i in df[df['batch_index']==49999].index:\n",
        "        df['signal_shift_-2'][i] = np.nan\n",
        "    for i in df[df['batch_index']==49998].index:\n",
        "        df['signal_shift_-2'][i] = np.nan\n",
        "    \n",
        "    df = df.drop(columns=['batch', 'batch_index', 'batch_slices', 'batch_slices2'])\n",
        "\n",
        "    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels']]:\n",
        "        df[c+'_msignal'] = df[c] - df['signal']\n",
        "        \n",
        "    df = df.replace([np.inf, -np.inf], np.nan)    \n",
        "    df.fillna(0, inplace=True)\n",
        "    gc.collect()q\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEXVH0TnPgHN",
        "colab_type": "text"
      },
      "source": [
        "## 3 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ana-214TI-U",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 start from a baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjLMb_UaTGyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}