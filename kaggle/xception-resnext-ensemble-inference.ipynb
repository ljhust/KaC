{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnext & Xception Ensemble (Inference)\n",
    "\n",
    "- This kernel outputs the ensemble of the results from https://www.kaggle.com/khoongweihao/frames-per-video-viz and https://www.kaggle.com/greatgamedota/xception-binary-classifier-inference (not original, modified learning rate and epochs)\n",
    "- Frames per video at 64 (best found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnext Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ae23f6465764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error"
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_dir = \"/kaggle/input/deepfake-detection-challenge/test_videos/\"\n",
    "\n",
    "test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n",
    "frame_h = 5\n",
    "frame_l = 5\n",
    "len(test_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/input/blazeface-pytorch\")\n",
    "sys.path.insert(0, \"/kaggle/input/deepfakes-inference-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from blazeface import BlazeFace\n",
    "facedet = BlazeFace().to(gpu)\n",
    "facedet.load_weights(\"/kaggle/input/blazeface-pytorch/blazeface.pth\")\n",
    "facedet.load_anchors(\"/kaggle/input/blazeface-pytorch/anchors.npy\")\n",
    "_ = facedet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from helpers.read_video_1 import VideoReader\n",
    "from helpers.face_extract_1 import FaceExtractor\n",
    "\n",
    "frames_per_video = 64 #frame_h * frame_l\n",
    "video_reader = VideoReader()\n",
    "video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "normalize_transform = Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n",
    "    h, w = img.shape[:2]\n",
    "    if w > h:\n",
    "        h = h * size // w\n",
    "        w = size\n",
    "    else:\n",
    "        w = w * size // h\n",
    "        h = size\n",
    "\n",
    "    resized = cv2.resize(img, (w, h), interpolation=resample)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def make_square_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = 0\n",
    "    b = size - h\n",
    "    l = 0\n",
    "    r = size - w\n",
    "    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MyResNeXt(models.resnet.ResNet):\n",
    "    def __init__(self, training=True):\n",
    "        super(MyResNeXt, self).__init__(block=models.resnet.Bottleneck,\n",
    "                                        layers=[3, 4, 6, 3], \n",
    "                                        groups=32, \n",
    "                                        width_per_group=4)\n",
    "        self.fc = nn.Linear(2048, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/kaggle/input/deepfakes-inference-demo/resnext.pth\", map_location=gpu)\n",
    "\n",
    "model = MyResNeXt().to(gpu)\n",
    "model.load_state_dict(checkpoint)\n",
    "_ = model.eval()\n",
    "\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_on_video(video_path, batch_size):\n",
    "    try:\n",
    "        # Find the faces for N frames in the video.\n",
    "        faces = face_extractor.process_video(video_path)\n",
    "\n",
    "        # Only look at one face per frame.\n",
    "        face_extractor.keep_only_best_face(faces)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            # NOTE: When running on the CPU, the batch size must be fixed\n",
    "            # or else memory usage will blow up. (Bug in PyTorch?)\n",
    "            x = np.zeros((batch_size, input_size, input_size, 3), dtype=np.uint8)\n",
    "\n",
    "            # If we found any faces, prepare them for the model.\n",
    "            n = 0\n",
    "            for frame_data in faces:\n",
    "                for face in frame_data[\"faces\"]:\n",
    "                    # Resize to the model's required input size.\n",
    "                    # We keep the aspect ratio intact and add zero\n",
    "                    # padding if necessary.                    \n",
    "                    resized_face = isotropically_resize_image(face, input_size)\n",
    "                    resized_face = make_square_image(resized_face)\n",
    "\n",
    "                    if n < batch_size:\n",
    "                        x[n] = resized_face\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        print(\"WARNING: have %d faces but batch size is %d\" % (n, batch_size))\n",
    "                    \n",
    "                    # Test time augmentation: horizontal flips.\n",
    "                    # TODO: not sure yet if this helps or not\n",
    "                    #x[n] = cv2.flip(resized_face, 1)\n",
    "                    #n += 1\n",
    "\n",
    "            if n > 0:\n",
    "                x = torch.tensor(x, device=gpu).float()\n",
    "\n",
    "                # Preprocess the images.\n",
    "                x = x.permute((0, 3, 1, 2))\n",
    "\n",
    "                for i in range(len(x)):\n",
    "                    x[i] = normalize_transform(x[i] / 255.)\n",
    "\n",
    "                # Make a prediction, then take the average.\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(x)\n",
    "                    y_pred = torch.sigmoid(y_pred.squeeze())\n",
    "                    return y_pred[:n].mean().item()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Prediction error on video %s: %s\" % (video_path, str(e)))\n",
    "\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def predict_on_video_set(videos, num_workers):\n",
    "    def process_file(i):\n",
    "        filename = videos[i]\n",
    "        y_pred = predict_on_video(os.path.join(test_dir, filename), batch_size=frames_per_video)\n",
    "        return y_pred\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "        predictions = ex.map(process_file, range(len(videos)))\n",
    "\n",
    "    return list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "speed_test = False  # you have to enable this manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if speed_test:\n",
    "    start_time = time.time()\n",
    "    speedtest_videos = test_videos[:5]\n",
    "    predictions = predict_on_video_set(speedtest_videos, num_workers=4)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Elapsed %f sec. Average per video: %f sec.\" % (elapsed, elapsed / len(speedtest_videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e89e754d975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_on_video_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_videos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_on_video_set' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'predict_on_video_set' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "predictions = predict_on_video_set(test_videos, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df_resnext = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})\n",
    "submission_df_resnext.to_csv(\"submission_resnext.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install ../input/deepfake-xception-trained-model/pytorchcv-0.0.55-py2.py3-none-any.whl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_dir = \"/kaggle/input/deepfake-detection-challenge/test_videos/\"\n",
    "\n",
    "test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])\n",
    "len(test_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/input/blazeface-pytorch\")\n",
    "sys.path.insert(0, \"/kaggle/input/deepfakes-inference-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from blazeface import BlazeFace\n",
    "facedet = BlazeFace().to(gpu)\n",
    "facedet.load_weights(\"/kaggle/input/blazeface-pytorch/blazeface.pth\")\n",
    "facedet.load_anchors(\"/kaggle/input/blazeface-pytorch/anchors.npy\")\n",
    "_ = facedet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from helpers.read_video_1 import VideoReader\n",
    "from helpers.face_extract_1 import FaceExtractor\n",
    "\n",
    "frames_per_video = 64 # originally 4\n",
    "\n",
    "video_reader = VideoReader()\n",
    "video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "normalize_transform = Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def isotropically_resize_image(img, size, resample=cv2.INTER_AREA):\n",
    "    h, w = img.shape[:2]\n",
    "    if w > h:\n",
    "        h = h * size // w\n",
    "        w = size\n",
    "    else:\n",
    "        w = w * size // h\n",
    "        h = size\n",
    "\n",
    "    resized = cv2.resize(img, (w, h), interpolation=resample)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def make_square_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = 0\n",
    "    b = size - h\n",
    "    l = 0\n",
    "    r = size - w\n",
    "    return cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!ls ../input/deepfake-xception-trained-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model\n",
    "model = get_model(\"xception\", pretrained=False)\n",
    "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Pooling, self).__init__()\n",
    "    \n",
    "    self.p1 = nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.p2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x1 = self.p1(x)\n",
    "    x2 = self.p2(x)\n",
    "    return (x1+x2) * 0.5\n",
    "\n",
    "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)))\n",
    "\n",
    "class Head(torch.nn.Module):\n",
    "  def __init__(self, in_f, out_f):\n",
    "    super(Head, self).__init__()\n",
    "    \n",
    "    self.f = nn.Flatten()\n",
    "    self.l = nn.Linear(in_f, 512)\n",
    "    self.d = nn.Dropout(0.5)\n",
    "    self.o = nn.Linear(512, out_f)\n",
    "    self.b1 = nn.BatchNorm1d(in_f)\n",
    "    self.b2 = nn.BatchNorm1d(512)\n",
    "    self.r = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.f(x)\n",
    "    x = self.b1(x)\n",
    "    x = self.d(x)\n",
    "\n",
    "    x = self.l(x)\n",
    "    x = self.r(x)\n",
    "    x = self.b2(x)\n",
    "    x = self.d(x)\n",
    "\n",
    "    out = self.o(x)\n",
    "    return out\n",
    "\n",
    "class FCN(torch.nn.Module):\n",
    "  def __init__(self, base, in_f):\n",
    "    super(FCN, self).__init__()\n",
    "    self.base = base\n",
    "    self.h1 = Head(in_f, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.base(x)\n",
    "    return self.h1(x)\n",
    "\n",
    "net = []\n",
    "model = FCN(model, 2048)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load('../input/deepfake-xception-trained-model/model.pth')) # new, updated\n",
    "net.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_on_video(video_path, batch_size):\n",
    "    try:\n",
    "        # Find the faces for N frames in the video.\n",
    "        faces = face_extractor.process_video(video_path)\n",
    "\n",
    "        # Only look at one face per frame.\n",
    "        face_extractor.keep_only_best_face(faces)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            # NOTE: When running on the CPU, the batch size must be fixed\n",
    "            # or else memory usage will blow up. (Bug in PyTorch?)\n",
    "            x = np.zeros((batch_size, input_size, input_size, 3), dtype=np.uint8)\n",
    "\n",
    "            # If we found any faces, prepare them for the model.\n",
    "            n = 0\n",
    "            for frame_data in faces:\n",
    "                for face in frame_data[\"faces\"]:\n",
    "                    # Resize to the model's required input size.\n",
    "                    # We keep the aspect ratio intact and add zero\n",
    "                    # padding if necessary.                    \n",
    "                    resized_face = isotropically_resize_image(face, input_size)\n",
    "                    resized_face = make_square_image(resized_face)\n",
    "\n",
    "                    if n < batch_size:\n",
    "                        x[n] = resized_face\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        print(\"WARNING: have %d faces but batch size is %d\" % (n, batch_size))\n",
    "                    \n",
    "                    # Test time augmentation: horizontal flips.\n",
    "                    # TODO: not sure yet if this helps or not\n",
    "                    #x[n] = cv2.flip(resized_face, 1)\n",
    "                    #n += 1\n",
    "\n",
    "            if n > 0:\n",
    "                x = torch.tensor(x, device=gpu).float()\n",
    "\n",
    "                # Preprocess the images.\n",
    "                x = x.permute((0, 3, 1, 2))\n",
    "\n",
    "                for i in range(len(x)):\n",
    "                    x[i] = normalize_transform(x[i] / 255.)\n",
    "#                     x[i] = x[i] / 255.\n",
    "\n",
    "                # Make a prediction, then take the average.\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(x)\n",
    "                    y_pred = torch.sigmoid(y_pred.squeeze())\n",
    "                    return y_pred[:n].mean().item()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Prediction error on video %s: %s\" % (video_path, str(e)))\n",
    "\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def predict_on_video_set(videos, num_workers):\n",
    "    def process_file(i):\n",
    "        filename = videos[i]\n",
    "        y_pred = predict_on_video(os.path.join(test_dir, filename), batch_size=frames_per_video)\n",
    "        return y_pred\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "        predictions = ex.map(process_file, range(len(videos)))\n",
    "\n",
    "    return list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "speed_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if speed_test:\n",
    "    start_time = time.time()\n",
    "    speedtest_videos = test_videos[:5]\n",
    "    predictions = predict_on_video_set(speedtest_videos, num_workers=4)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"Elapsed %f sec. Average per video: %f sec.\" % (elapsed, elapsed / len(speedtest_videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.eval()\n",
    "predictions = predict_on_video_set(test_videos, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df_xception = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})\n",
    "submission_df_xception.to_csv(\"submission_xception.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df_resnext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df_xception.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Resnext and Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"filename\": test_videos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "r1 = 0.46441\n",
    "r2 = 0.52189\n",
    "total = r1 + r2\n",
    "r11 = r1/total\n",
    "r22 = r2/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df[\"label\"] = r22*submission_df_resnext[\"label\"] + r11*submission_df_xception[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}